{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b925854-4ee7-4cba-8910-0d2b33291e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Data saved to flipkart_laptop.xlsx.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up the WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')  # Run in headless mode (optional)\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Start with the first page\n",
    "base_url = 'https://www.flipkart.com/search?q=laptops&as=on&as-show=on&otracker=AS_Query_OrganicAutoSuggest_3_6_na_na_na&otracker1=AS_Query_OrganicAutoSuggest_3_6_na_na_na&as-pos=3&as-type=RECENT&suggestionId=laptops&requestId=4fce71ec-d25e-4cbe-a179-d51d3931ad7f&as-backfill=on'\n",
    "driver.get(base_url)\n",
    "\n",
    "# Initialize an empty list to store product data\n",
    "product_data = []\n",
    "page_number = 1  # Keep track of the page number\n",
    "\n",
    "def extract_product_details():\n",
    "    products = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.tUxRFH'))\n",
    "    )\n",
    "    \n",
    "    # Add a print statement to show which page is being scraped\n",
    "    print(f'Scraping page {page_number}...')\n",
    "\n",
    "    for product in products:\n",
    "        product_info = {}\n",
    "        \n",
    "        try:\n",
    "            # Extract title\n",
    "            title_elements = product.find_elements(By.CSS_SELECTOR, 'div.KzDlHZ')\n",
    "            title = title_elements[0].text if title_elements else 'No title'\n",
    "            product_info['title'] = title\n",
    "        except Exception:\n",
    "            product_info['title'] = 'No title'\n",
    "        \n",
    "        try:\n",
    "            # Extract price\n",
    "            price_elements = product.find_elements(By.CSS_SELECTOR, 'div.Nx9bqj._4b5DiR')\n",
    "            price = price_elements[0].text if price_elements else 'No price'\n",
    "            product_info['price'] = price\n",
    "        except Exception:\n",
    "            product_info['price'] = 'No price'\n",
    "        \n",
    "        try:\n",
    "            # Extract ratings\n",
    "            rating_elements = product.find_elements(By.CSS_SELECTOR, 'div.XQDdHH')\n",
    "            rating = rating_elements[0].text if rating_elements else 'No rating'\n",
    "            product_info['rating'] = rating\n",
    "        except Exception:\n",
    "            product_info['rating'] = 'No rating'\n",
    "        \n",
    "        try:\n",
    "            # Extract number of reviews\n",
    "            reviews_elements = product.find_elements(By.CSS_SELECTOR, 'span.Wphh3N')\n",
    "            reviews = reviews_elements[0].text if reviews_elements else 'No reviews'\n",
    "            product_info['reviews'] = reviews\n",
    "        except Exception:\n",
    "            product_info['reviews'] = 'No reviews'\n",
    "        \n",
    "        # Append the product info to the list\n",
    "        product_data.append(product_info)\n",
    "\n",
    "\n",
    "# Function to handle pagination\n",
    "def get_next_page():\n",
    "    try:\n",
    "        # Find the \"Next\" button\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, 'a._9QVEpD')\n",
    "        next_button.click()  # Click on the next button\n",
    "        time.sleep(5)  # Wait for the next page to load\n",
    "        return True  # Return True if successfully moved to next page\n",
    "    except Exception as e:\n",
    "        return False  # Return False if there's no next button\n",
    "\n",
    "\n",
    "# Loop through all pages, stop at 30 pages\n",
    "while page_number <= 30:\n",
    "    extract_product_details()\n",
    "    \n",
    "    # Check if there's a next page or stop after 30 pages\n",
    "    if not get_next_page():\n",
    "        print(f'Scraping completed. Total pages scraped: {page_number}')\n",
    "        break\n",
    "    \n",
    "    page_number += 1\n",
    "\n",
    "# Close the driver after scraping\n",
    "driver.quit()\n",
    "\n",
    "# Convert the product data into a DataFrame and save it to an Excel file\n",
    "df = pd.DataFrame(product_data)\n",
    "df.to_excel('flipkart_laptop.xlsx', index=False)  # Use .to_excel() for Excel format\n",
    "print('Data saved to flipkart_laptop.xlsx.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
